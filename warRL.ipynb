        "%matplotlib inline\n",
        "plt.rcParams.update({\"font.size\": 12})\\n",
        "plt.rcParams[\"figure.dpi\"] = 300\\n"
        "def visualize_paths_on_benchmark_maps(env, policy, map_folder=\"maps/\", num_maps=4, grid_cols=2, save=False):\n",
        "    fig, axs = plt.subplots(grid_rows, grid_cols, figsize=(grid_cols * 4, grid_rows * 4), dpi=300)\n",
        "        ax.imshow(env.cost_map, cmap='Blues', alpha=0.3, origin='lower')\n",
        "        ax.imshow(env.risk_map, cmap='Reds', alpha=0.3, origin='lower')\n",
        "visualize_paths_on_benchmark_maps(env, policy, map_folder=\"maps/\", num_maps=4)"
        "# === 1. Mean Reward Curves with Confidence Intervals ===\n",
        "def smooth(x, window=10):\n",
        "    return np.convolve(x, np.ones(window)/window, mode='valid')\n",
        "\n",
        "def plot_mean_reward_curves(all_rewards, names, window=10):\n",
        "    colors = plt.cm.tab10.colors\n",
        "    plt.figure(figsize=(10,5))\n",
        "    for idx, (runs, name) in enumerate(zip(all_rewards, names)):\n",
        "        runs = np.array(runs)\n",
        "        mean = runs.mean(axis=0)\n",
        "        std = runs.std(axis=0)\n",
        "        ci = 1.96 * std / np.sqrt(runs.shape[0])\n",
        "        sm_mean = smooth(mean, window)\n",
        "        sm_ci = smooth(ci, window)\n",
        "        episodes = np.arange(len(sm_mean))\n",
        "        plt.plot(episodes, sm_mean, label=name, color=colors[idx], lw=2)\n",
        "        plt.fill_between(episodes, sm_mean - sm_ci, sm_mean + sm_ci, color=colors[idx], alpha=0.2)\n",
        "    plt.title('Training Reward Curves', fontsize=14)\n",
        "    plt.xlabel('Episode', fontsize=12)\n",
        "    plt.ylabel('External Reward', fontsize=12)\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",

        "reward_runs = [\n",
        "    [rewards_ppo_only],\n",
        "    [rewards_ppo_icm],\n",
        "    [rewards_ppo_icm_plan],\n",
        "    [rewards_ppo_count],\n",
        "    [rewards_ppo_rnd]\n",
        "plot_mean_reward_curves(reward_runs, model_names)\n",
        "\n",
        "# === 2. Grouped Bar Chart Comparison ===\n",
        "def plot_grouped_bars(names, success, steps, planner_use, intrinsic):\n",
        "    metrics = [success, planner_use, steps, intrinsic]\n",
        "    labels = ['Success Rate (%)', 'Planner Usage (%)', 'Avg Steps', 'Avg Intrinsic']\n",
        "    x = np.arange(len(names))\n",
        "    width = 0.18\n",
        "    fig, ax = plt.subplots(figsize=(10,6))\n",
        "    for i, metric in enumerate(metrics):\n",
        "        means = [np.mean(m) * (100 if i < 2 else 1) for m in metric]\n",
        "        stds = [np.std(m) * (100 if i < 2 else 1) for m in metric]\n",
        "        ax.bar(x + (i-1.5)*width, means, width, yerr=stds, capsize=4, label=labels[i])\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(names, rotation=30)\n",
        "    ax.set_ylabel('Value')\n",
        "    ax.set_title('Comparative Evaluation of Exploration Methods', fontsize=14)\n",
        "    ax.legend()\n",
        "    ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",

        "model_names = ['PPO Only', 'PPO + ICM', 'PPO + ICM + Planner', 'PPO + Count-Based', 'PPO + RND']\n",
        "success_rates = [[success_ppo_only], [success_ppo_icm], [success_ppo_icm_plan], [success_ppo_count], [success_ppo_rnd]]\n",
        "steps_to_goal = [[steps_ppo_only], [steps_ppo_icm], [steps_ppo_icm_plan], [steps_ppo_count], [steps_ppo_rnd]]\n",
        "planner_usages = [[planner_pct_ppo_only], [planner_pct_ppo_icm], [planner_pct_ppo_icm_plan], [planner_pct_ppo_count], [planner_pct_ppo_rnd]]\n",
        "intrinsic_rewards = [[0], [intrinsic_ppo_icm], [intrinsic_ppo_icm_plan], [0], [intrinsic_ppo_rnd]]\n",
        "plot_grouped_bars(model_names, success_rates, steps_to_goal, planner_usages, intrinsic_rewards)\n",
        "    visualize_paths_on_benchmark_maps(env, model, map_folder=\"maps/\", num_maps=4)\n",
        "clean_means, clean_stds = [], []\n",
        "noisy_means, noisy_stds = [], []\n",
        "print('Generalization on Unseen Test Maps')\n",
        "    mean_r, std_r = evaluate_generalization(model, env, map_folder='test_maps/', add_noise=False)\n",
        "    print(f'✅ {name} (Clean Maps): Mean Reward = {mean_r:.2f}, Std = {std_r:.2f}')\n",
        "    clean_means.append(mean_r); clean_stds.append(std_r)\n",
        "print('\nGeneralization with Noisy Risk & Cost Maps')\n",
        "    mean_r, std_r = evaluate_generalization(model, env, map_folder='test_maps/', add_noise=True)\n",
        "    print(f'⚠️ {name} (Noisy Maps): Mean Reward = {mean_r:.2f}, Std = {std_r:.2f}')\n",
        "    noisy_means.append(mean_r); noisy_stds.append(std_r)\n",
        "\n",
        "def plot_generalization_results(names, clean_m, clean_s, noisy_m, noisy_s):\n",
        "    x = np.arange(len(names))\n",
        "    width = 0.35\n",
        "    fig, ax = plt.subplots(figsize=(8,5))\n",
        "    ax.bar(x - width/2, clean_m, width, yerr=clean_s, capsize=4, label='Clean', color='tab:blue')\n",
        "    ax.bar(x + width/2, noisy_m, width, yerr=noisy_s, capsize=4, label='Noisy', color='tab:orange')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(names, rotation=30)\n",
        "    ax.set_ylabel('Average Reward')\n",
        "    ax.set_title('Generalization Performance')\n",
        "    ax.legend()\n",
        "    ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_generalization_results(model_names, clean_means, clean_stds, noisy_means, noisy_stds)\n"
        "def plot_grouped_bars(names, success, steps, planner_use, intrinsic):\n",
        "    metrics = [success, planner_use, steps, intrinsic]\n",
        "    labels = ['Success Rate (%)', 'Planner Usage (%)', 'Avg Steps', 'Avg Intrinsic']\n",
        "    x = np.arange(len(names))\n",
        "    width = 0.18\n",
        "    fig, ax = plt.subplots(figsize=(10,6))\n",
        "    for i, metric in enumerate(metrics):\n",
        "        means = [np.mean(m) * (100 if i < 2 else 1) for m in metric]\n",
        "        stds = [np.std(m) * (100 if i < 2 else 1) for m in metric]\n",
        "        ax.bar(x + (i-1.5)*width, means, width, yerr=stds, capsize=4, label=labels[i])\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(names, rotation=30)\n",
        "    ax.set_ylabel('Value')\n",
        "    ax.set_title('Model Comparison')\n",
        "    ax.legend()\n",
        "    ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
      "source": [
        "# Hyperparameter sweep for planner weight and beta\n",
        "planner_weight_list = [0.5, 1.0, 2.0]\n",
        "beta_list = [0.05, 0.1]\n",
        "results = {}\n",
        "for pw in planner_weight_list:\n",
        "    for b in beta_list:\n",
        "        config = {\"cost_weight\": pw, \"risk_weight\": pw}\n",
        "        policy_model = PPOPolicy(input_dim, action_dim)\n",
        "        opt = optim.Adam(policy_model.parameters(), lr=3e-4)\n",
        "        rewards, _, _, _, _, _, _, _ = train_agent(env, policy_model, icm, planner, opt, optim_icm,\n",
        "                                                     use_icm=True, use_planner=True,\n",
        "                                                     beta=b, planner_weights=config, num_episodes=100)\n",
        "        results[(pw, b)] = np.mean(rewards)\n",
        "print('Hyperparameter results:', results)\n"
      ],
}
